{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T22:35:24.092822900Z",
     "start_time": "2024-07-11T22:35:16.786572300Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb201 import NB201Benchmark\n",
    "import numpy as np\n",
    "from warmstart.utils_templates import FullTemplate\n",
    "import ConfigSpace as CS\n",
    "from ConfigSpace import Configuration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import ollama\n",
    "import torchvision\n",
    "from exp_baselines.bayesmark.data import ProblemType\n",
    "import ast\n",
    "from llambo.llambo import LLAMBO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load NB201 Benchmark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    op_0_to_1, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_0_to_2, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_0_to_3, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_1_to_2, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_1_to_3, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_2_to_3, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "\n",
      "Numpy representation:  [3. 3. 3. 3. 3. 0.]\n",
      "Dict representation:  {'op_0_to_1': 'nor_conv_1x1', 'op_0_to_2': 'nor_conv_1x1', 'op_0_to_3': 'nor_conv_1x1', 'op_1_to_2': 'nor_conv_1x1', 'op_1_to_3': 'nor_conv_1x1', 'op_2_to_3': 'none'}\n",
      "Configuration(values={\n",
      "  'op_0_to_1': 'nor_conv_1x1',\n",
      "  'op_0_to_2': 'nor_conv_1x1',\n",
      "  'op_0_to_3': 'nor_conv_1x1',\n",
      "  'op_1_to_2': 'nor_conv_1x1',\n",
      "  'op_1_to_3': 'nor_conv_1x1',\n",
      "  'op_2_to_3': 'none',\n",
      "})\n",
      "Test error: 10.550000 %\n",
      "Runtime 4278.069735 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DonatSinani\\AppData\\Local\\Temp\\ipykernel_30796\\238710382.py:6: DeprecationWarning: `Configuration` act's like a dictionary. Please use `dict(config)` instead of `get_dictionary` if you explicitly need a `dict`\n",
      "  print(\"Dict representation: \", config.get_dictionary())\n",
      "C:\\Users\\DonatSinani\\AppData\\Local\\Temp\\ipykernel_30796\\238710382.py:9: DeprecationWarning: `Configuration` act's like a dictionary. Please use `dict(config)` instead of `get_dictionary` if you explicitly need a `dict`\n",
      "  new_config = Configuration(cs, values=config.get_dictionary())\n"
     ]
    }
   ],
   "source": [
    "b = NB201Benchmark(path=\"./nb201.pkl\", dataset='cifar10')\n",
    "cs = b.get_configuration_space()\n",
    "config = cs.sample_configuration()  # samples a configuration uniformly at random\n",
    "print(cs)\n",
    "print(\"Numpy representation: \", config.get_array())\n",
    "print(\"Dict representation: \", config.get_dictionary())\n",
    "\n",
    "#configuration from a dict\n",
    "new_config = Configuration(cs, values=config.get_dictionary())\n",
    "print(new_config)\n",
    "\n",
    "y, cost = b.objective_function(config)\n",
    "print(\"Test error: %f %%\" % y)\n",
    "print(\"Runtime %f s\" % cost)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T22:35:24.201114100Z",
     "start_time": "2024-07-11T22:35:24.097080500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arguments for LLAMBO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "task_context = {\n",
    "    'model': 'CNN',\n",
    "    'task': 'classification',\n",
    "    'tot_feats': 32 * 32 * 3,\n",
    "    'cat_feats': 0,\n",
    "    'num_feat': 32 * 32 * 3,\n",
    "    'n_classes': 10,\n",
    "    'metric': 'loss',\n",
    "    'lower_is_better': True,\n",
    "    'num_samples': 50000,\n",
    "    'hyperparameter_constraints': {\n",
    "        'op_0_to_1': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        # [type, transform, [min_value, max_value]]\n",
    "        'op_0_to_2': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_0_to_3': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_1_to_2': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_1_to_3': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_2_to_3': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def init_f():\n",
    "    return\n",
    "\n",
    "\n",
    "def eval_point(config):\n",
    "    new_config = Configuration(b.get_configuration_space(), values=config)\n",
    "    res = b.objective_function(new_config)\n",
    "    res_dict = {\n",
    "        \"score\": res[0],\n",
    "        \"train_time\": res[1]\n",
    "    }\n",
    "    return config, res_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T22:35:24.260360900Z",
     "start_time": "2024-07-11T22:35:24.209696600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Huggingface"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\").to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_length=512)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ollama"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat_engine = \"llama3\"\n",
    "model = ollama.pull(chat_engine)\n",
    "response = ollama.chat(model=\"llama3\", messages=[{'role': 'user', 'content': 'Why is the sky blue?'}])\n",
    "print(response)\n",
    "ollama.list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True)\n",
    "def fetch_statistics(dict, dataset):\n",
    "    images = dataset.data\n",
    "    labels = dataset.targets\n",
    "\n",
    "    images_np = np.array(images)\n",
    "    labels_np = np.array(labels)\n",
    "\n",
    "    pixel_mean = np.mean(images_np / 255.)\n",
    "    pixel_std = np.std(images_np / 255.)\n",
    "\n",
    "    class_counts = np.bincount(labels_np)\n",
    "    class_distribution = class_counts / len(labels_np)\n",
    "\n",
    "    dict['pixel_mean'] = pixel_mean\n",
    "    dict['pixel_std'] = pixel_std\n",
    "    dict['class_distribution'] = class_distribution.tolist()\n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "task_context = fetch_statistics(task_context, trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T22:35:26.899356100Z",
     "start_time": "2024-07-11T22:35:24.223557500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Warmstart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "config = \"No_Context\"\n",
    "metric = \"acc\"\n",
    "NUM_SEEDS = 10\n",
    "problem_type = ProblemType.clf\n",
    "\n",
    "\n",
    "def extract_configs_from_response(response):\n",
    "    content = response['message']['content']\n",
    "    start = content.find(\"[\")\n",
    "    end = content.rfind(\"]\") + 1\n",
    "    list_str = content[start:end]\n",
    "    configurations = ast.literal_eval(list_str)\n",
    "    return configurations\n",
    "\n",
    "\n",
    "def is_dict_valid_in_config_space(d, config_space):\n",
    "    try:\n",
    "        # Attempt to create a Configuration object with the given dictionary and config space\n",
    "        config = CS.Configuration(config_space, values=d)\n",
    "        return True\n",
    "    except:\n",
    "        # Return False if the dictionary is not valid\n",
    "        return False\n",
    "    # Function to check if all dictionaries in a list are valid in the given configuration space\n",
    "\n",
    "\n",
    "def check_all_list(parsed_dicts, config_space):\n",
    "    for idx, d in enumerate(parsed_dicts):\n",
    "        if not is_dict_valid_in_config_space(d, config_space):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def obtain_all_list_valid(resp, config_space):\n",
    "    if check_all_list(resp, config_space):\n",
    "        return resp\n",
    "    print(\"fail\")\n",
    "\n",
    "\n",
    "def generate_init_conf(n_samples):\n",
    "    template_object = FullTemplate(context=config, provide_ranges=True)\n",
    "    input_prompt = template_object.add_context(config_space=cs, num_recommendation=n_samples, task_dict=task_context)\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{'role': 'user', 'content': input_prompt}])\n",
    "    configs = extract_configs_from_response(response)\n",
    "    return obtain_all_list_valid(configs, cs)\n",
    "\n",
    "#print(generate_init_conf(3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T22:35:26.937170800Z",
     "start_time": "2024-07-11T22:35:26.911657300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Llambo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n",
      "[Search settings]: \n",
      "\tn_candidates: 10, n_templates: 2, n_gens: 10, \n",
      "\talpha: 0.1, n_initial_samples: 5, n_trials: 25, \n",
      "\tusing warping: False, ablation: None, shuffle_features: False\n",
      "[Task]: \n",
      "\ttask type: classification, sm: discriminative, lower is better: True\n",
      "Hyperparameter search space: \n",
      "{'op_0_to_1': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_0_to_2': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_0_to_3': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_1_to_2': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_1_to_3': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_2_to_3': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']]}\n",
      "======================================================================================================================================================\n",
      "[Initialization] COMPLETED: 5 points evaluated...\n",
      "[Initialization] COMPLETED: best fval: 7.2400, best generalization fval: 7.2400\n",
      "======================================================================================================================================================\n",
      "Adjusted alpha: 0.1 | [original alpha: 0.1], desired fval: 6.636667\n",
      "====================================================================================================\n",
      "EXAMPLE ACQUISITION PROMPT\n",
      "Length of prompt templates: 2\n",
      "Length of query templates: 2\n",
      "The following are examples of performance of a CNN measured in test loss and the corresponding model architecture configurations. The model is evaluated on a image classification task containing 10 classes. The dataset contains 50000 images and each image has height 32, width 32, and 3 channels. The allowable choices for the architectures are:\n",
      "- op_0_to_1: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_0_to_2: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_0_to_3: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_1_to_2: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_1_to_3: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_2_to_3: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "Recommend a configuration that can achieve the target performance of 6.636667. Do not recommend categorical choices outside of given lists. Recommend categorical choices with highest possible precision, as requested by the allowed ranges. Your response must only contain the predicted configuration, in the format ## configuration ##. Please provide a configuration different from the provided ones.\n",
      "\n",
      "Performance: 7.240000\n",
      "Hyperparameter configuration: ## op_0_to_1: nor_conv_3x3, op_0_to_2: skip_connect, op_0_to_3: avg_pool_3x3, op_1_to_2: none, op_1_to_3: nor_conv_1x1, op_2_to_3: skip_connect ##\n",
      "Performance: 8.886667\n",
      "Hyperparameter configuration: ## op_0_to_1: skip_connect, op_0_to_2: avg_pool_3x3, op_0_to_3: nor_conv_1x1, op_1_to_2: none, op_1_to_3: nor_conv_3x3, op_2_to_3: skip_connect ##\n",
      "Performance: 10.805000\n",
      "Hyperparameter configuration: ## op_0_to_1: avg_pool_3x3, op_0_to_2: nor_conv_1x1, op_0_to_3: none, op_1_to_2: skip_connect, op_1_to_3: avg_pool_3x3, op_2_to_3: nor_conv_3x3 ##\n",
      "Performance: 7.816667\n",
      "Hyperparameter configuration: ## op_0_to_1: none, op_0_to_2: skip_connect, op_0_to_3: avg_pool_3x3, op_1_to_2: nor_conv_1x1, op_1_to_3: none, op_2_to_3: nor_conv_3x3 ##\n",
      "Performance: 13.273333\n",
      "Hyperparameter configuration: ## op_0_to_1: skip_connect, op_0_to_2: nor_conv_3x3, op_0_to_3: none, op_1_to_2: avg_pool_3x3, op_1_to_3: skip_connect, op_2_to_3: avg_pool_3x3 ##\n",
      "Performance: 6.636667\n",
      "Hyperparameter configuration:\n",
      "====================================================================================================\n",
      "Attempt: 0, number of proposed candidate points: 2,  number of accepted candidate points: 2\n",
      "Attempt: 1, number of proposed candidate points: 2,  number of accepted candidate points: 4\n",
      "Attempt: 2, number of proposed candidate points: 2,  number of accepted candidate points: 6\n",
      "======================================================================================================================================================\n",
      "EXAMPLE POINTS PROPOSED\n",
      "      op_0_to_1     op_0_to_2     op_0_to_3     op_1_to_2     op_1_to_3  \\\n",
      "0  nor_conv_3x3  skip_connect  nor_conv_3x3  avg_pool_3x3  nor_conv_1x1   \n",
      "1  nor_conv_3x3  skip_connect  avg_pool_3x3  nor_conv_3x3          none   \n",
      "2  nor_conv_3x3          none  skip_connect  avg_pool_3x3  nor_conv_1x1   \n",
      "3  nor_conv_3x3  skip_connect  nor_conv_1x1  avg_pool_3x3  nor_conv_1x1   \n",
      "4  nor_conv_3x3  skip_connect  avg_pool_3x3  nor_conv_1x1  nor_conv_3x3   \n",
      "5  skip_connect  avg_pool_3x3  nor_conv_1x1          none  avg_pool_3x3   \n",
      "\n",
      "      op_2_to_3  \n",
      "0          none  \n",
      "1  skip_connect  \n",
      "2  nor_conv_3x3  \n",
      "3  skip_connect  \n",
      "4  skip_connect  \n",
      "5  skip_connect  \n",
      "======================================================================================================================================================\n",
      "****************************************************************************************************\n",
      "Number of all_prompt_templates: 2\n",
      "Number of query_examples: 6\n",
      "The following are architecture configurations for a CNN and the corresponding performance measured in test loss. The model is evaluated on a image classification task and the label contains 10 classes. The dataset contains 50000 images and each image has height 32, width 32, and 3 channels. Your response should only contain the predicted test loss in the format ## performance ##.\n",
      "Hyperparameter configuration: op_0_to_1 is nor_conv_3x3, op_0_to_2 is skip_connect, op_0_to_3 is avg_pool_3x3, op_1_to_2 is none, op_1_to_3 is nor_conv_1x1, op_2_to_3 is skip_connect\n",
      "Performance: ## 7.240000 ##\n",
      "Hyperparameter configuration: op_0_to_1 is skip_connect, op_0_to_2 is avg_pool_3x3, op_0_to_3 is nor_conv_1x1, op_1_to_2 is none, op_1_to_3 is nor_conv_3x3, op_2_to_3 is skip_connect\n",
      "Performance: ## 8.886667 ##\n",
      "Hyperparameter configuration: op_0_to_1 is avg_pool_3x3, op_0_to_2 is nor_conv_1x1, op_0_to_3 is none, op_1_to_2 is skip_connect, op_1_to_3 is avg_pool_3x3, op_2_to_3 is nor_conv_3x3\n",
      "Performance: ## 10.805000 ##\n",
      "Hyperparameter configuration: op_0_to_1 is none, op_0_to_2 is skip_connect, op_0_to_3 is avg_pool_3x3, op_1_to_2 is nor_conv_1x1, op_1_to_3 is none, op_2_to_3 is nor_conv_3x3\n",
      "Performance: ## 7.816667 ##\n",
      "Hyperparameter configuration: op_0_to_1 is skip_connect, op_0_to_2 is nor_conv_3x3, op_0_to_3 is none, op_1_to_2 is avg_pool_3x3, op_1_to_3 is skip_connect, op_2_to_3 is avg_pool_3x3\n",
      "Performance: ## 13.273333 ##\n",
      "Hyperparameter configuration: op_0_to_1 is nor_conv_3x3, op_0_to_2 is skip_connect, op_0_to_3 is nor_conv_3x3, op_1_to_2 is avg_pool_3x3, op_1_to_3 is nor_conv_1x1, op_2_to_3 is none\n",
      "Performance: \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m llambo\u001B[38;5;241m.\u001B[39mseed \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# run optimization\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m configs, fvals \u001B[38;5;241m=\u001B[39m \u001B[43mllambo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\DLLab\\DeepLearningLab\\llambo\\llambo.py:180\u001B[0m, in \u001B[0;36mLLAMBO.optimize\u001B[1;34m(self, test_metric)\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m150\u001B[39m)\n\u001B[0;32m    179\u001B[0m \u001B[38;5;66;03m# select candidate point\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m sel_candidate_point, cost, time_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msurrogate_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect_query_point\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobserved_configs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m                                                                                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobserved_fvals\u001B[49m\u001B[43m[\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m                                                                                    \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[43m                                                                                \u001B[49m\u001B[43mcandidate_points\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m trial_cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m cost\n\u001B[0;32m    185\u001B[0m trial_query_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m time_taken\n",
      "File \u001B[1;32m~\\Desktop\\DLLab\\DeepLearningLab\\llambo\\discriminative_sm.py:226\u001B[0m, in \u001B[0;36mLLM_DIS_SM.select_query_point\u001B[1;34m(self, observed_configs, observed_fvals, candidate_configs)\u001B[0m\n\u001B[0;32m    223\u001B[0m     observed_configs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarping_transformer\u001B[38;5;241m.\u001B[39mwarp(observed_configs)\n\u001B[0;32m    224\u001B[0m     candidate_configs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarping_transformer\u001B[38;5;241m.\u001B[39mwarp(candidate_configs)\n\u001B[1;32m--> 226\u001B[0m y_mean, y_std, cost, time_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluate_candidate_points\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobserved_configs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobserved_fvals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m                                                                  \u001B[49m\u001B[43mcandidate_configs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlower_is_better:\n\u001B[0;32m    229\u001B[0m     best_fval \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(observed_fvals\u001B[38;5;241m.\u001B[39mto_numpy())\n",
      "File \u001B[1;32m~\\Desktop\\DLLab\\DeepLearningLab\\llambo\\discriminative_sm.py:190\u001B[0m, in \u001B[0;36mLLM_DIS_SM._evaluate_candidate_points\u001B[1;34m(self, observed_configs, observed_fvals, candidate_configs, use_context, use_feature_semantics, return_ei)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of query_examples: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(query_examples)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28mprint\u001B[39m(all_prompt_templates[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mformat(Q\u001B[38;5;241m=\u001B[39mquery_examples[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQ\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[1;32m--> 190\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_prompt_templates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_examples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    192\u001B[0m y_mean, y_std, success_rate, tot_cost, tot_tokens, time_taken \u001B[38;5;241m=\u001B[39m response\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecalibrator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\DLLab\\DeepLearningLab\\llambo\\discriminative_sm.py:132\u001B[0m, in \u001B[0;36mLLM_DIS_SM._predict\u001B[1;34m(self, all_prompt_templates, query_examples)\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(sample_preds) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_gens:\n\u001B[0;32m    130\u001B[0m         sample_preds\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mnan)\n\u001B[1;32m--> 132\u001B[0m     tot_cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([x[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m sample_response])\n\u001B[0;32m    133\u001B[0m     tot_tokens \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([x[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m sample_response])\n\u001B[0;32m    134\u001B[0m all_preds\u001B[38;5;241m.\u001B[39mappend(sample_preds)\n",
      "File \u001B[1;32m~\\Desktop\\DLLab\\DeepLearningLab\\llambo\\discriminative_sm.py:132\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(sample_preds) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_gens:\n\u001B[0;32m    130\u001B[0m         sample_preds\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mnan)\n\u001B[1;32m--> 132\u001B[0m     tot_cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m sample_response])\n\u001B[0;32m    133\u001B[0m     tot_tokens \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([x[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m sample_response])\n\u001B[0;32m    134\u001B[0m all_preds\u001B[38;5;241m.\u001B[39mappend(sample_preds)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "llambo = LLAMBO(task_context, sm_mode='discriminative', n_candidates=10, n_templates=2, n_gens=10,\n",
    "                alpha=0.1, n_initial_samples=5, n_trials=25,\n",
    "                init_f=generate_init_conf,\n",
    "                bbox_eval_f=eval_point,\n",
    "                chat_engine=\"llama3\")\n",
    "llambo.seed = 0\n",
    "\n",
    "# run optimization\n",
    "configs, fvals = llambo.optimize(test_metric=\"score\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
