{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T20:40:50.169433Z",
     "start_time": "2024-07-10T20:40:35.155640800Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb201 import NB201Benchmark\n",
    "import numpy as np\n",
    "from warmstart.utils_templates import FullTemplate\n",
    "import ConfigSpace as CS\n",
    "from ConfigSpace import Configuration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import ollama\n",
    "import torchvision\n",
    "from exp_baselines.bayesmark.data import ProblemType\n",
    "import ast\n",
    "from llambo.llambo import LLAMBO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load NB201 Benchmark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    op_0_to_1, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_0_to_2, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_0_to_3, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_1_to_2, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_1_to_3, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "    op_2_to_3, Type: Categorical, Choices: {none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3}, Default: none\n",
      "\n",
      "Numpy representation:  [4. 3. 0. 4. 2. 1.]\n",
      "Dict representation:  {'op_0_to_1': 'nor_conv_3x3', 'op_0_to_2': 'nor_conv_1x1', 'op_0_to_3': 'none', 'op_1_to_2': 'nor_conv_3x3', 'op_1_to_3': 'avg_pool_3x3', 'op_2_to_3': 'skip_connect'}\n",
      "Configuration(values={\n",
      "  'op_0_to_1': 'nor_conv_3x3',\n",
      "  'op_0_to_2': 'nor_conv_1x1',\n",
      "  'op_0_to_3': 'none',\n",
      "  'op_1_to_2': 'nor_conv_3x3',\n",
      "  'op_1_to_3': 'avg_pool_3x3',\n",
      "  'op_2_to_3': 'skip_connect',\n",
      "})\n",
      "Test error: 7.370000 %\n",
      "Runtime 3333.234787 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DonatSinani\\AppData\\Local\\Temp\\ipykernel_25552\\238710382.py:6: DeprecationWarning: `Configuration` act's like a dictionary. Please use `dict(config)` instead of `get_dictionary` if you explicitly need a `dict`\n",
      "  print(\"Dict representation: \", config.get_dictionary())\n",
      "C:\\Users\\DonatSinani\\AppData\\Local\\Temp\\ipykernel_25552\\238710382.py:9: DeprecationWarning: `Configuration` act's like a dictionary. Please use `dict(config)` instead of `get_dictionary` if you explicitly need a `dict`\n",
      "  new_config = Configuration(cs, values=config.get_dictionary())\n"
     ]
    }
   ],
   "source": [
    "b = NB201Benchmark(path=\"./nb201.pkl\", dataset='cifar10')\n",
    "cs = b.get_configuration_space()\n",
    "config = cs.sample_configuration()  # samples a configuration uniformly at random\n",
    "print(cs)\n",
    "print(\"Numpy representation: \", config.get_array())\n",
    "print(\"Dict representation: \", config.get_dictionary())\n",
    "\n",
    "#configuration from a dict\n",
    "new_config = Configuration(cs, values=config.get_dictionary())\n",
    "print(new_config)\n",
    "\n",
    "y, cost = b.objective_function(config)\n",
    "print(\"Test error: %f %%\" % y)\n",
    "print(\"Runtime %f s\" % cost)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T20:41:01.665268800Z",
     "start_time": "2024-07-10T20:41:01.466973200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arguments for LLAMBO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "task_context = {\n",
    "    'model': 'CNN',\n",
    "    'task': 'classification',\n",
    "    'tot_feats': 32 * 32 * 3,\n",
    "    'cat_feats': 0,\n",
    "    'num_feat': 32 * 32 * 3,\n",
    "    'n_classes': 10,\n",
    "    'metric': 'loss',\n",
    "    'lower_is_better': True,\n",
    "    'num_samples': 50000,\n",
    "    'hyperparameter_constraints': {\n",
    "        'op_0_to_1': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        # [type, transform, [min_value, max_value]]\n",
    "        'op_0_to_2': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_0_to_3': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_1_to_2': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_1_to_3': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]],\n",
    "        'op_2_to_3': ['categorical', None, [\"none\", \"skip_connect\", \"avg_pool_3x3\", \"nor_conv_1x1\", \"nor_conv_3x3\"]]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def init_f():\n",
    "    return\n",
    "\n",
    "\n",
    "def eval_point(config):\n",
    "    new_config = Configuration(b.get_configuration_space(), values=config)\n",
    "    res = b.objective_function(new_config)\n",
    "    res_dict = {\n",
    "        \"score\": res[0],\n",
    "        \"train_time\": res[1]\n",
    "    }\n",
    "    return config, res_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T20:41:05.046905600Z",
     "start_time": "2024-07-10T20:41:05.000463700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Huggingface"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\").to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_length=512)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ollama"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat_engine = \"llama3\"\n",
    "model = ollama.pull(chat_engine)\n",
    "response = ollama.chat(model=\"llama3\", messages=[{'role': 'user', 'content': 'Why is the sky blue?'}])\n",
    "print(response)\n",
    "ollama.list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True)\n",
    "def fetch_statistics(dict, dataset):\n",
    "    images = dataset.data\n",
    "    labels = dataset.targets\n",
    "\n",
    "    images_np = np.array(images)\n",
    "    labels_np = np.array(labels)\n",
    "\n",
    "    pixel_mean = np.mean(images_np / 255.)\n",
    "    pixel_std = np.std(images_np / 255.)\n",
    "\n",
    "    class_counts = np.bincount(labels_np)\n",
    "    class_distribution = class_counts / len(labels_np)\n",
    "\n",
    "    dict['pixel_mean'] = pixel_mean\n",
    "    dict['pixel_std'] = pixel_std\n",
    "    dict['class_distribution'] = class_distribution.tolist()\n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "task_context = fetch_statistics(task_context, trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T20:41:17.918688200Z",
     "start_time": "2024-07-10T20:41:13.677781100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Warmstart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "config = \"No_Context\"\n",
    "metric = \"acc\"\n",
    "NUM_SEEDS = 10\n",
    "problem_type = ProblemType.clf\n",
    "\n",
    "\n",
    "def extract_configs_from_response(response):\n",
    "    content = response['message']['content']\n",
    "    start = content.find(\"[\")\n",
    "    end = content.rfind(\"]\") + 1\n",
    "    list_str = content[start:end]\n",
    "    configurations = ast.literal_eval(list_str)\n",
    "    return configurations\n",
    "\n",
    "\n",
    "def is_dict_valid_in_config_space(d, config_space):\n",
    "    try:\n",
    "        # Attempt to create a Configuration object with the given dictionary and config space\n",
    "        config = CS.Configuration(config_space, values=d)\n",
    "        return True\n",
    "    except:\n",
    "        # Return False if the dictionary is not valid\n",
    "        return False\n",
    "    # Function to check if all dictionaries in a list are valid in the given configuration space\n",
    "\n",
    "\n",
    "def check_all_list(parsed_dicts, config_space):\n",
    "    for idx, d in enumerate(parsed_dicts):\n",
    "        if not is_dict_valid_in_config_space(d, config_space):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def obtain_all_list_valid(resp, config_space):\n",
    "    if check_all_list(resp, config_space):\n",
    "        return resp\n",
    "    print(\"fail\")\n",
    "\n",
    "\n",
    "def generate_init_conf(n_samples):\n",
    "    template_object = FullTemplate(context=config, provide_ranges=True)\n",
    "    input_prompt = template_object.add_context(config_space=cs, num_recommendation=n_samples, task_dict=task_context)\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{'role': 'user', 'content': input_prompt}])\n",
    "    configs = extract_configs_from_response(response)\n",
    "    return obtain_all_list_valid(configs, cs)\n",
    "\n",
    "#print(generate_init_conf(3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T20:41:21.248763300Z",
     "start_time": "2024-07-10T20:41:21.194342Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Llambo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n",
      "[Search settings]: \n",
      "\tn_candidates: 10, n_templates: 2, n_gens: 10, \n",
      "\talpha: 0.1, n_initial_samples: 5, n_trials: 25, \n",
      "\tusing warping: False, ablation: None, shuffle_features: False\n",
      "[Task]: \n",
      "\ttask type: classification, sm: discriminative, lower is better: True\n",
      "Hyperparameter search space: \n",
      "{'op_0_to_1': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_0_to_2': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_0_to_3': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_1_to_2': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_1_to_3': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']],\n",
      " 'op_2_to_3': ['categorical',\n",
      "               None,\n",
      "               ['none',\n",
      "                'skip_connect',\n",
      "                'avg_pool_3x3',\n",
      "                'nor_conv_1x1',\n",
      "                'nor_conv_3x3']]}\n",
      "======================================================================================================================================================\n",
      "[Initialization] COMPLETED: 5 points evaluated...\n",
      "[Initialization] COMPLETED: best fval: 7.4500, best generalization fval: 7.4500\n",
      "======================================================================================================================================================\n",
      "Adjusted alpha: 0.1 | [original alpha: 0.1], desired fval: 6.180667\n",
      "====================================================================================================\n",
      "EXAMPLE ACQUISITION PROMPT\n",
      "Length of prompt templates: 2\n",
      "Length of query templates: 2\n",
      "The following are examples of performance of a CNN measured in loss and the corresponding model architecture configurations. The model is evaluated on a image classification task containing 10 classes. The dataset contains 50000 images and each image has height 32, width 32, and 3 channels. The allowable choices for the architectures are:\n",
      "- op_0_to_1: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_0_to_2: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_0_to_3: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_1_to_2: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_1_to_3: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "- op_2_to_3: [none, skip_connect, avg_pool_3x3, nor_conv_1x1, nor_conv_3x3] (categorical)\n",
      "Recommend a configuration that can achieve the target performance of 6.180667. Do not recommend categorical choices outside of given lists. Recommend categorical choices with highest possible precision, as requested by the allowed ranges. Your response must only contain the predicted configuration, in the format ## configuration ##.\n",
      "\n",
      "Performance: 7.450000\n",
      "Hyperparameter configuration: ## op_0_to_1: nor_conv_3x3, op_0_to_2: skip_connect, op_0_to_3: avg_pool_3x3, op_1_to_2: none, op_1_to_3: skip_connect, op_2_to_3: nor_conv_1x1 ##\n",
      "Performance: 13.706667\n",
      "Hyperparameter configuration: ## op_0_to_1: skip_connect, op_0_to_2: avg_pool_3x3, op_0_to_3: nor_conv_1x1, op_1_to_2: none, op_1_to_3: avg_pool_3x3, op_2_to_3: skip_connect ##\n",
      "Performance: 8.900000\n",
      "Hyperparameter configuration: ## op_0_to_1: avg_pool_3x3, op_0_to_2: nor_conv_1x1, op_0_to_3: none, op_1_to_2: skip_connect, op_1_to_3: nor_conv_3x3, op_2_to_3: avg_pool_3x3 ##\n",
      "Performance: 20.143333\n",
      "Hyperparameter configuration: ## op_0_to_1: none, op_0_to_2: avg_pool_3x3, op_0_to_3: nor_conv_3x3, op_1_to_2: skip_connect, op_1_to_3: avg_pool_3x3, op_2_to_3: skip_connect ##\n",
      "Performance: 11.223333\n",
      "Hyperparameter configuration: ## op_0_to_1: skip_connect, op_0_to_2: nor_conv_1x1, op_0_to_3: avg_pool_3x3, op_1_to_2: none, op_1_to_3: none, op_2_to_3: skip_connect ##\n",
      "Performance: 6.180667\n",
      "Hyperparameter configuration:\n",
      "====================================================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m llambo\u001B[38;5;241m.\u001B[39mseed \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# run optimization\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m configs, fvals \u001B[38;5;241m=\u001B[39m \u001B[43mllambo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\DLLab\\DeepLearningLab\\llambo\\llambo.py:170\u001B[0m, in \u001B[0;36mLLAMBO.optimize\u001B[1;34m(self, test_metric)\u001B[0m\n\u001B[0;32m    168\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    169\u001B[0m \u001B[38;5;66;03m# get candidate point\u001B[39;00m\n\u001B[1;32m--> 170\u001B[0m candidate_points, cost, time_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macq_func\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_candidate_points\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobserved_configs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    171\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobserved_fvals\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    173\u001B[0m trial_cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m cost\n\u001B[0;32m    174\u001B[0m trial_query_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m time_taken\n",
      "File \u001B[1;32m~\\Desktop\\DLLab\\DeepLearningLab\\llambo\\acquisition_function.py:486\u001B[0m, in \u001B[0;36mLLM_ACQ.get_candidate_points\u001B[1;34m(self, observed_configs, observed_fvals, use_feature_semantics, use_context, alpha)\u001B[0m\n\u001B[0;32m    484\u001B[0m retry \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m number_candidate_points \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m5\u001B[39m:\n\u001B[1;32m--> 486\u001B[0m     llm_responses \u001B[38;5;241m=\u001B[39m \u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_async_generate_concurrently\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_templates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_templates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    488\u001B[0m     candidate_points \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    489\u001B[0m     tot_cost \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DLLabProject\\lib\\asyncio\\runners.py:33\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(main, debug)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03mThis function runs the passed coroutine, taking care of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m    asyncio.run(main())\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m events\u001B[38;5;241m.\u001B[39m_get_running_loop() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 33\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masyncio.run() cannot be called from a running event loop\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m coroutines\u001B[38;5;241m.\u001B[39miscoroutine(main):\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma coroutine was expected, got \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(main))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "llambo = LLAMBO(task_context, sm_mode='discriminative', n_candidates=10, n_templates=2, n_gens=10,\n",
    "                alpha=0.1, n_initial_samples=5, n_trials=25,\n",
    "                init_f=generate_init_conf,\n",
    "                bbox_eval_f=eval_point,\n",
    "                chat_engine=\"llama3\")\n",
    "llambo.seed = 0\n",
    "\n",
    "# run optimization\n",
    "configs, fvals = llambo.optimize(test_metric=\"score\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
