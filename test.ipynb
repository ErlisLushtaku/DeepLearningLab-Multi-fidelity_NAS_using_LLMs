{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nb201 import NB201Benchmark\n",
    "import numpy as np\n",
    "import openai\n",
    "from warmstart.utils_templates import FullTemplate\n",
    "import ConfigSpace as CS\n",
    "import google.generativeai as genai\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load NB201 Benchmark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = NB201Benchmark(path=\"./nb201.pkl\", dataset='cifar10')\n",
    "cs = b.get_configuration_space()\n",
    "config = cs.sample_configuration()  # samples a configuration uniformly at random\n",
    "\n",
    "print(cs)\n",
    "print(\"Numpy representation: \", config.get_array())\n",
    "print(\"Dict representation: \", config.get_dictionary())\n",
    "\n",
    "y, cost = b.objective_function(config)\n",
    "print(\"Test error: %f %%\" % y)\n",
    "print(\"Runtime %f s\" % cost)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arguments for LLAMBO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# task_context = {\n",
    "#     'model': 'CNN',\n",
    "#     'task': 'classification',\n",
    "#     'tot_feats': 32 * 32 * 3,\n",
    "#     'cat_feats': 0,\n",
    "#     'num_feats': 32 * 32 * 3,\n",
    "#     'n_classes': 10,\n",
    "#     'metric': 'accuracy',\n",
    "#     'lower_is_better': False,\n",
    "#     'num_samples': 50000,\n",
    "#     'hyperparameter_constraints': {\n",
    "#         'max_depth': ['int', 'linear', [1, 15]],  # [type, transform, [min_value, max_value]]\n",
    "#         'max_features': ['float', 'logit', [0.01, 0.99]],\n",
    "#         'min_impurity_decrease': ['float', 'linear', [0.0, 0.5]],\n",
    "#         'min_samples_leaf': ['float', 'logit', [0.01, 0.49]],\n",
    "#         'min_samples_split': ['float', 'logit', [0.01, 0.99]],\n",
    "#         'min_weight_fraction_leaf': ['float', 'logit', [0.01, 0.49]]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "task_context = {\n",
    "    'model': 'RandomForest',\n",
    "    'task': 'classification',\n",
    "    'tot_feats': 30,\n",
    "    'cat_feats': 0,\n",
    "    'num_feat': 30,\n",
    "    'n_classes': 2,\n",
    "    'metric': 'accuracy',\n",
    "    'lower_is_better': False,\n",
    "    'num_samples': 455,\n",
    "    'hyperparameter_constraints': {\n",
    "        'max_depth': ['int', 'linear', [1, 15]],  # [type, transform, [min_value, max_value]]\n",
    "        'max_features': ['float', 'logit', [0.01, 0.99]],\n",
    "        'min_impurity_decrease': ['float', 'linear', [0.0, 0.5]],\n",
    "        'min_samples_leaf': ['float', 'logit', [0.01, 0.49]],\n",
    "        'min_samples_split': ['float', 'logit', [0.01, 0.99]],\n",
    "        'min_weight_fraction_leaf': ['float', 'logit', [0.01, 0.49]]\n",
    "    }\n",
    "}\n",
    "\n",
    "#me bo ni mapping t ints n operations n NAS\n",
    "a = {\n",
    "    \"op_0_to_1\": ['int', 'linear', [1, 15]],\n",
    "    \"op_0_to_2\": 2,\n",
    "    \"op_0_to_3\": 2,\n",
    "    \"op_1_to_2\": 2,\n",
    "    \"op_1_to_3\": 2,\n",
    "    \"op_2_to_3\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "#qetu me define warmstarting\n",
    "def init_f():\n",
    "    return\n",
    "\n",
    "\n",
    "#should use the NB201 benchmark eval\n",
    "def eval_point():\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test gemma2b-it from huggingface"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\").to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_length=512)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ollama"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ollama.pull(\"llama3\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = ollama.chat(model=\"llama3\", messages=[{'role': 'user', 'content': 'Why is the sky blue?'}])\n",
    "print(response)\n",
    "ollama.list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Warmstart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = \"No_Context\"\n",
    "metric = \"acc\"\n",
    "exp_model = \"RF\"\n",
    "NUM_INIT = 5\n",
    "NUM_SEEDS = 10\n",
    "\n",
    "template_object = FullTemplate(context=config, provide_ranges=True)\n",
    "\n",
    "input_prompt = template_object.add_context(config_space=cs, num_recommendation=NUM_INIT, task_dict=task_context)\n",
    "response = ollama.chat(model=\"llama3\", messages=[{'role': 'user', 'content': input_prompt}])\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
